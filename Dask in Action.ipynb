{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask in Action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this BE we'll look at deploying Dask in two different ways, on an HPC cluster and on GCP using Kubernetes. You'll then use a Dask cluster to run a hyper-parameter search, which will be the basis for your grade. This notebook is just for presentation - you will write and hand in your own notebooks depending on which Dask installation you choose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outline\n",
    "\n",
    "+ [Dask on Rainman](#rainman)\n",
    "+ [Dask on GCP with Kubernetes](#kubernetes)\n",
    "+ [Testing Dask](#testing)\n",
    "+ [HyperParameter Optimization](#hyperparam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"rainman\">Dask on Rainman</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first way we'll look at Dask is on Rainman, the High-Performance Computing cluster for students at ISAE. It is available at `rainman.isae.fr`, but only from internal networks. The architecture looks like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rainman](img/rainman.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://icampus.isae-supaero.fr/rainman-architecture-materielle-du-supercalculateur-etudiant?lang=fr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To connect to rainman, do:\n",
    "```bash\n",
    "local$ ssh USER@rainmain\n",
    "```\n",
    "with your student username. You must be on the internal network.\n",
    "\n",
    "`dask` is already installed on rainman, so to use it, do:\n",
    "```bash\n",
    "rainman$ module load python/3.7\n",
    "rainman$ source activate dask\n",
    "rainman$ jupyter-notebook --no-browser --port=PORT --ip=IP\n",
    "```\n",
    "\n",
    "For `PORT`, pick a number between 8000 and 9999; if it doesn't work try a different one. For `IP`, if you are connected to `rainman1` use `10.162.9.3` and for `rainman2` use `10.162.9.4`. You should now be able to access the jupyter server from your machine at http://IP:PORT/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the jupyter server is working, we can use the Dask [SLURMCluster](https://jobqueue.dask.org/en/latest/generated/dask_jobqueue.SLURMCluster.html#dask_jobqueue.SLURMCluster) class to launch batch jobs, creating workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_jobqueue import SLURMCluster\n",
    "\n",
    "cluster = SLURMCluster(cores=16,\n",
    "                       memory=\"60GB\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       dashboard_address=\":8787\", # different from before, change it if there's a warning\n",
    "                       job_extra=[\"--reservation=root_2\"], # only between 9h and 19h on 11/03/2020\n",
    "                       queue=\"p16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To launch the workers, run `scale`. Please don't run more than 2 jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.scale(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By inspecting the cluster, we can see the Dask dashboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you successfully run the client and can see the dashboard, you can move on to [Testing Dask](#testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"kubernetes\">Dask on GCP with Kubernetes</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A second way we can use Dask is through Kubernetes on GCP. Kubernetes is a container orchestration system which can be used to deploy many different applications.\n",
    "\n",
    "![kubernetes](img/kubernetes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow the instructions [here](https://zero-to-jupyterhub.readthedocs.io/en/latest/google/step-zero-gcp.html) to set up Kubernetes until the Helm verification step at the end of [this page](https://zero-to-jupyterhub.readthedocs.io/en/latest/setup-jupyterhub/setup-helm.html). You do not need to fully configure JupyterHub.\n",
    "\n",
    "Here are all of the commands which I used, but make sure to read the documentation to understand what they mean. I used Google Cloud Shell and would recommend it over using a local shell.\n",
    "\n",
    "```\n",
    "> gcloud container clusters create --machine-type n1-standard-2 --num-nodes 2 --zone europe-west1 --cluster-version latest mycluste\n",
    "> kubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=<GOOGLE-EMAIL-ACCOUNT>\n",
    "> curl https://raw.githubusercontent.com/kubernetes/helm/master/scripts/get | bash\n",
    "> kubectl --namespace kube-system create serviceaccount tiller\n",
    "> kubectl create clusterrolebinding tiller --clusterrole cluster-admin --serviceaccount=kube-system:tiller\n",
    "> helm init --service-account tiller --history-max 100 --wait\n",
    "> kubectl patch deployment tiller-deploy --namespace=kube-system --type=json --patch='[{\"op\": \"add\", \"path\": \"/spec/template/spec/containers/0/command\", \"value\": [\"/tiller\", \"--listen=localhost:44134\"]}]'\n",
    "```\n",
    "\n",
    "At this point you will have a Kubernetes cluster and helm and can move on to using it for installing Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should follow the [Dask installation instructions](https://docs.dask.org/en/latest/setup/kubernetes-helm.html), which use helm.\n",
    "\n",
    "```\n",
    "> helm repo add dask https://helm.dask.org/\n",
    "> helm repo update\n",
    "> helm install dask/dask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the documentation says, this will take a minute to start. You can watch the output of these to see when your workers are ready. They'll have external IPs once they're done:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "> kubectl get pods\n",
    "> kubectl get services\n",
    "```\n",
    "\n",
    "The output should look like this when they're ready:\n",
    "```\n",
    "NAME                           TYPE           CLUSTER-IP      EXTERNAL-IP    PORT(S)                       AGE\n",
    "kubernetes                     ClusterIP      10.35.240.1     <none>         443/TCP                       14m\n",
    "wobbling-lion-dask-jupyter     LoadBalancer   10.35.254.151   35.240.9.13    80:31100/TCP                  9m30s\n",
    "wobbling-lion-dask-scheduler   LoadBalancer   10.35.241.171   35.189.209.3   8786:31226/TCP,80:31891/TCP   9m30s\n",
    "```\n",
    "\n",
    "You can use the EXTERNAL IP to access the dask-jupyter service from your computer to see Jupyter and dask-scheduler to see the Dask dashboard. Your instances are now created, but they won't have the right Python packages installed. You can upgrade the environment by creating a `config.yaml` system and uploading it to your Google Cloud Shell (click on the three verticle dots, then \"Import File\").\n",
    "\n",
    "```\n",
    "worker:\n",
    "  replicas: 8\n",
    "  resources:\n",
    "    limits:\n",
    "      cpu: 2\n",
    "    requests:\n",
    "      cpu: 2\n",
    "  env:\n",
    "    - name: EXTRA_CONDA_PACKAGES\n",
    "      value: numba xarray dask-ml scikit-learn dask-xgboost -c conda-forge\n",
    "jupyter:\n",
    "  env:\n",
    "    - name: EXTRA_CONDA_PACKAGES\n",
    "      value: numba xarray dask-ml scikit-learn dask-xgboost matplotlib -c conda-forge\n",
    "scheduler:\n",
    "  env:\n",
    "    - name: EXTRA_CONDA_PACKAGES\n",
    "      value: dask-xgboost -c conda-forge\n",
    "```\n",
    "\n",
    "Run the following in your Google Cloud Shell to update:\n",
    "```\n",
    "helm upgrade wobbling-lion dask/dask -f config.yaml\n",
    "```\n",
    "\n",
    "Note that this may take a few minutes to update, since the workers are installing packages.\n",
    "\n",
    "The `config.yaml` in the documentation specifies requests 7.5G of memory for each node, which will make the nodes pend for a long time and is beyond the memory limit of the machine type specified above. You can increase the computational power by increasing the `replicas` and `cpu`.\n",
    "\n",
    "You should now be able to access Dask from Jupyter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client, config\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"testing\">Testing Dask</a>\n",
    "\n",
    "To test that our Dask installations are working, we'll look at a simple KMeans example. Copy the following code to your Dask notebook, whether on rainman or GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_ml.datasets\n",
    "import dask_ml.cluster\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale up: increase n_samples or n_features\n",
    "X, y = dask_ml.datasets.make_blobs(n_samples=1000000,\n",
    "                                   chunks=100000,\n",
    "                                   random_state=0,\n",
    "                                   centers=3)\n",
    "X = X.persist()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = dask_ml.cluster.KMeans(n_clusters=3, init_max_iter=2, oversampling_factor=10)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're done with a session, make sure to close your client. If you used rainman, also close the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close() # only for rainman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"hyperparam\">Hyperparameter Optimization</a>\n",
    "\n",
    "A task that works well in parallel computing is hyperparameter optimization. Machine learning models have a number of different parameters, and parameter combinations can be tested in parallel independently.\n",
    "\n",
    "For this assignment, you will perform hyperparameter optimization on the [Titanic](https://www.kaggle.com/c/titanic/data) dataset. You should follow the extensive hyperparameter optimization example in the [Dask documentation](https://examples.dask.org/machine-learning/hyperparam-opt.html). You will need to create a notebook in your Dask installation, and once you have it working, save the notebook and submit it in the LMS. \n",
    "\n",
    "To get started, download the Titanic data. You have to first [agree to the competition](https://www.kaggle.com/c/titanic/rules) and will need to [set your Kaggle API key](https://www.kaggle.com/docs/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions download -c titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "\n",
    "with ZipFile(\"titanic.zip\", \"r\") as zip:\n",
    "    zipObj.extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be graded on the following criteria:\n",
    "\n",
    "+ Reproducibility - does your notebook work when I run it? Make sure to specify which method (rainman or GCP)\n",
    "+ Completeness\n",
    "+ Prediction performance\n",
    "+ Compute performance - how fast is it?\n",
    "\n",
    "Bonus points for:\n",
    "+ Including Kaggle submission in your notebook\n",
    "+ Explanation (text and code comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
